from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum, max, avg
import sys



# Create a SparkSession
#spark = SparkSession.builder.appName("AdvancedDataFrameOperations").getOrCreate()

spark = SparkSession.builder \
    .appName("LocalSparkSession") \
    .master("local[*]") \
    .getOrCreate()

# Step 1: Create a sample DataFrame for sales transactions
data = [
    {"date": "2023-11-01", "product_id": "A", "quantity": 10, "price": 20.0, "product_category": "Category1"},
    {"date": "2023-11-01", "product_id": "B", "quantity": 5, "price": 30.0, "product_category": "Category2"},
    {"date": "2023-11-02", "product_id": "A", "quantity": 7, "price": 20.0, "product_category": "Category1"},
    {"date": "2023-11-02", "product_id": "C", "quantity": 3, "price": 40.0, "product_category": "Category3"},
    {"date": "2023-11-03", "product_id": "B", "quantity": 8, "price": 30.0, "product_category": "Category2"},
    {"date": "2023-11-03", "product_id": "C", "quantity": 4, "price": 40.0, "product_category": "Category3"},
]

df = spark.createDataFrame(data)

# Step 2: Create a table of product categories
product_categories_data = [
    ("Category1", "Category1 Description"),
    ("Category2", "Category2 Description"),
    ("Category3", "Category3 Description"),
]

product_categories = spark.createDataFrame(product_categories_data, ["product_category", "category_description"])


# Step 3: Calculate the total revenue generated by each product
product_revenue = df.groupBy("product_id").agg(sum(col("quantity") * col("price")).alias("total_revenue"))
print("Total Revenue by Product:")
product_revenue.show()

# Step 4: Find the date with the highest total revenue
date_max_revenue = df.groupBy("date").agg(sum(col("quantity") * col("price")).alias("total_revenue"))
date_max_revenue = date_max_revenue.orderBy("total_revenue", ascending=False).limit(1)
print("Date with Highest Total Revenue:")
date_max_revenue.show()


# Step 5: Calculate the average revenue per day
avg_daily_revenue = df.groupBy("date").agg(avg(col("quantity") * col("price")).alias("avg_daily_revenue"))
print("Average Revenue Per Day:")
avg_daily_revenue.show()

# Step 6: Calculate the total revenue for each product category
product_category_revenue = df.join(product_categories, "product_category", "left") \
    .groupBy("product_category", "category_description") \
    .agg(sum(col("quantity") * col("price")).alias("total_revenue"))

# Show the result
product_category_revenue.show()


# Stop the SparkSession
spark.stop()
